{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from utils import plot_loss_epoch, plot_mse, plot_pred_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidding_area = 1\n",
    "\n",
    "df = pd.read_csv(f\"data/NO{1}.csv\")\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df.set_index(\"timestamp\", inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add historic temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"past_consumption\"] = df[\"consumption\"].shift(1)\n",
    "df.rename(\n",
    "    columns={\"consumption\": \"next_consumption\", \"past_consumption\": \"consumption\"},\n",
    "    inplace=True,\n",
    ")\n",
    "df = df[[\"temperature\", \"consumption\", \"next_consumption\"]]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding time, day and year features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"time_of_day\"] = df.index.hour\n",
    "df[\"day_of_week\"] = df.index.dayofweek\n",
    "df[\"day_of_year\"] = df.index.dayofyear\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, shuffle=False)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = df_train.mean()\n",
    "train_std = df_train.std()\n",
    "\n",
    "df_train = (df_train - train_mean) / train_std\n",
    "df_val = (df_val - train_mean) / train_std\n",
    "df_test = (df_test - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting to tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = torch.tensor(df_train[\"next_consumption\"].values.astype(np.float32))\n",
    "features_train = torch.tensor(\n",
    "    df_train.drop(columns=\"next_consumption\").values.astype(np.float32)\n",
    ")\n",
    "\n",
    "target_val = torch.tensor(df_val[\"next_consumption\"].values.astype(np.float32))\n",
    "features_val = torch.tensor(\n",
    "    df_val.drop(columns=\"next_consumption\").values.astype(np.float32)\n",
    ")\n",
    "\n",
    "target_test = torch.tensor(df_test[\"next_consumption\"].values.astype(np.float32))\n",
    "features_test = torch.tensor(\n",
    "    df_test.drop(columns=\"next_consumption\").values.astype(np.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pytorch datasets and data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor = TensorDataset(features_train, target_train)\n",
    "train_loader = DataLoader(train_tensor, batch_size=64, shuffle=True)\n",
    "\n",
    "val_tensor = TensorDataset(features_val, target_val)\n",
    "val_loader = DataLoader(val_tensor, batch_size=64, shuffle=False)\n",
    "\n",
    "test_tensor = TensorDataset(features_test, target_test)\n",
    "test_loader = DataLoader(\n",
    "    test_tensor, batch_size=25, shuffle=False\n",
    ")  # 25 because one day has 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "\n",
    "# Define model\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(5, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12, 6),\n",
    "            nn.Linear(6, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = FeedForward().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m---> 12\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m     15\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(pred, y)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "\n",
    "losses = []\n",
    "losses_show = []\n",
    "val_losses = []\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = []\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.view(-1, 1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        if len(losses) > 20:\n",
    "            losses_show.append(sum(losses[-20:]) / 20)\n",
    "        else:\n",
    "            losses_show.append(losses[-1])\n",
    "\n",
    "    val_loss = []\n",
    "    for batch, (X, y) in enumerate(val_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.view(-1, 1))\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    avg_val_loss = sum(val_loss) / len(val_loss)\n",
    "    print(f\"Epoch {e+1}, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "models_directory = \"models\"\n",
    "\n",
    "if not os.path.exists(models_directory):\n",
    "    os.makedirs(models_directory)\n",
    "\n",
    "torch.save(model.state_dict(), \"models/fnn.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_epoch(losses_show, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing using Step-by-Step Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "\n",
    "    for batch, (X, y) in enumerate(test_loader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        preds = []\n",
    "        i = 0\n",
    "        pred = 0\n",
    "        for f, t in zip(X, y):\n",
    "            if i > 0:\n",
    "                f[1] = pred\n",
    "                pred = model(f)\n",
    "                preds.append(pred.item())\n",
    "            elif i == 0:\n",
    "                pred = model(f)\n",
    "                preds.append(pred.item())\n",
    "            i += 1\n",
    "        predictions.append([preds, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting predictions and targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pred_target(predictions, train_mean, train_std, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Mean Squared Error with Deviation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mse(predictions, train_mean, train_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "it3030",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
